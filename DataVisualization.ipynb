{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dac11",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052174ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOTS = {\"val_blurred\": Path(\"./val_blurred\")}\n",
    "\n",
    "def load_data(dataset, transformation=None, n_train=None, n_test=None, seed=None):\n",
    "    \"\"\"\n",
    "    Loads the data from the dataset, applies given transformation and splits the data to the given split.\n",
    "\n",
    "    Args: \n",
    "        dataset: name of the dataset\n",
    "        transformation: transformations to be applied to the data\n",
    "        n_train: number of train samples\n",
    "        n_test: number of test samples\n",
    "        seed: for reproducible shuffling\n",
    "\n",
    "    Returns:\n",
    "        sample_train: lazy (sample, label) generator for training\n",
    "        sample_test: lazy (sample, label) generator for testing\n",
    "    \"\"\"\n",
    "    dataset_root = DATASET_ROOTS.get(dataset)\n",
    "\n",
    "    if dataset_root is None:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")\n",
    "    dataset_root = dataset_root.expanduser().resolve() # normalize so the loader works across diff machines\n",
    "\n",
    "    class_dirs = sorted([d for d in dataset_root.iterdir() if d.is_dir()])\n",
    "    class_dirs_indexed = {cls.name: idx for idx, cls in enumerate(class_dirs)}\n",
    "    \n",
    "    samples = []\n",
    "    for cls_dir in class_dirs:\n",
    "        label = class_dirs_indexed[cls_dir.name]\n",
    "        for img_path in cls_dir.glob(\"*.jpg\"):\n",
    "            samples.append((img_path, label))\n",
    "\n",
    "    random.shuffle(samples)\n",
    "\n",
    "    total = len(samples)\n",
    "    if n_train is None and n_test is None:\n",
    "        n_train = int(0.8 * total)\n",
    "        n_test = total - n_train\n",
    "    elif n_train is None:\n",
    "        n_train = total - n_test\n",
    "    elif n_test is None:\n",
    "        n_test = total - n_train\n",
    "    elif n_train + n_test > total:\n",
    "        raise ValueError('Sample sizes combined exceed the total data size')\n",
    "\n",
    "    train_samples = samples[:n_train]\n",
    "    test_samples = samples[n_train:n_train + n_test]\n",
    "\n",
    "    def generator(items):\n",
    "        for img_path, label in items:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "                data = transformation(img) if transformation else np.array(img)\n",
    "            yield data, label\n",
    "\n",
    "    return generator(train_samples), generator(test_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09024391",
   "metadata": {},
   "source": [
    "## Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da988fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array_64(img):\n",
    "    return np.array(img.resize((64, 64)))\n",
    "\n",
    "tr = 15\n",
    "ts = 15\n",
    "train_gen, test_gen = load_data(\"val_blurred\", transformation=to_array_64, n_train = tr, n_test = ts)\n",
    "train_batch = [next(train_gen) for _ in range(tr)]\n",
    "test_batch = [next(test_gen) for _ in range(ts)]\n",
    "\n",
    "# for idx, (img, label) in enumerate(train_batch):\n",
    "#     print(f\"train[{idx}] -> shape {img.shape}, dtype {img.dtype}, label {label}\")\n",
    "# for idx, (img, label) in enumerate(test_batch):\n",
    "#     print(f\"test[{idx}]  -> shape {img.shape}, dtype {img.dtype}, label {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b62e2",
   "metadata": {},
   "source": [
    "## Visualize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(samples, rows=None, cols=None, outfile=None):\n",
    "    \"\"\"\n",
    "    Shows given samples in the wanted format (rows x columns) and saves the output to the specifed file.\n",
    "\n",
    "    Args: \n",
    "        samples: data to be represented (plain images or labled images)\n",
    "        rows: number of rows\n",
    "        cols: number of columns\n",
    "        outfile: file in which the figure will be saved (if None shows the figure directly)\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(samples)\n",
    "\n",
    "    if cols is None:\n",
    "        cols = 5\n",
    "    if rows is None:\n",
    "        rows = math.ceil(n / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n",
    "    axes = np.atleast_1d(axes).flatten()\n",
    "\n",
    "    for ax, sample in zip(axes, samples):\n",
    "        if isinstance(sample, tuple) and len(sample) == 2:  # in case we only imput images without labels\n",
    "            img, label = sample\n",
    "        else:\n",
    "            img, label = sample, None\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        if label is not None:\n",
    "            ax.set_title(str(label))\n",
    "\n",
    "    for ax in axes[len(samples):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if outfile is not None:\n",
    "        fig.savefig(outfile, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
